import logging
import os
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
import google.generativeai as genai

# –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini API
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-1.5-pro-latest")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
from aiogram.client.default import DefaultBotProperties
bot = Bot(token=TELEGRAM_BOT_TOKEN, default=DefaultBotProperties(parse_mode="MarkdownV2"))
dp = Dispatcher()
logging.basicConfig(level=logging.INFO)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –æ—Ç Gemini
def format_gemini_response(text: str) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç Gemini –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram (MarkdownV2).
    """
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    special_chars = r"_*[]()~`>#+-=|{}.!"
    for ch in special_chars:
        text = text.replace(ch, f"\\{ch}")

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–ª–æ–∫–∏ –∫–æ–¥–∞ (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å)
    if "```" in text:
        parts = text.split("```")
        for i in range(len(parts)):
            if i % 2 == 1:  # –≠—Ç–æ –±–ª–æ–∫ –∫–æ–¥–∞
                parts[i] = f"```{parts[i]}```"
        text = "".join(parts)

    return text

# –ü—Ä–æ–≤–µ—Ä–∫–∞, –æ–±—Ä–∞—â–∞—é—Ç—Å—è –ª–∏ –∫ –±–æ—Ç—É
def is_bot_mentioned(message: types.Message):
    triggers = ["vai", "–≤–∞–π", "VAI", "Vai", "–í–∞–π"]
    text = message.text.lower()
    return (
        any(trigger in text for trigger in triggers) or 
        (message.reply_to_message and message.reply_to_message.from_user.id == bot.id)
    )

# –ö–æ–º–∞–Ω–¥–∞ /start
@dp.message(Command("start"))
async def start_handler(message: types.Message):
    text = f"–ü—Ä–∏–≤–µ—Ç, {message.from_user.full_name}! ü§ñ –Ø AI –æ—Ç Vandili. –°–ø—Ä–∞—à–∏–≤–∞–π —á—Ç–æ —É–≥–æ–¥–Ω–æ!"
    await message.answer(format_gemini_response(text), parse_mode="MarkdownV2")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∑–∞–ø—Ä–æ—Å –≤ Gemini
@dp.message()
async def chat_with_gemini(message: types.Message):
    if message.chat.type != 'private' and not is_bot_mentioned(message):
        return

    # –£–±–∏—Ä–∞–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –∑–∞–ø—Ä–æ—Å–∞
    user_text = message.text
    for trigger in ["vai", "–≤–∞–π", "VAI", "Vai", "–í–∞–π"]:
        user_text = user_text.replace(trigger, "").strip()

    try:
        response = model.generate_content(user_text).text

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –æ—Ç Gemini
        formatted_response = format_gemini_response(response)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        await message.answer(formatted_response, parse_mode="MarkdownV2")
    
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        await message.answer(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: `{format_gemini_response(str(e))}`", parse_mode="MarkdownV2")

# –ó–∞–ø—É—Å–∫
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    logging.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    asyncio.run(main())